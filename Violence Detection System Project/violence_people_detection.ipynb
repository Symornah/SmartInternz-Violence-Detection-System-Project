{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P117c5McDlUG"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2NXgVgFD5au",
    "outputId": "44c0c1ab-75df-4ced-b2f4-44323031534c"
   },
   "outputs": [],
   "source": [
    "#Violence Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jH9MhIOmD65k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time \n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "\n",
    "def print_results(video, limit=None):\n",
    "        #fig=plt.figure(figsize=(16, 30))\n",
    "        # if not os.path.exists('output'):\n",
    "        #     os.mkdir('output')\n",
    "\n",
    "        print(\"Loading model ...\")\n",
    "        model = load_model('model.h5')\n",
    "        Q = deque(maxlen=128)\n",
    "        vs = cv2.VideoCapture(video)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "        writer = None\n",
    "        (W, H) = (None, None)\n",
    "        count = 0     \n",
    "        while True:\n",
    "            # read the next frame from the file\n",
    "            (grabbed, frame) = vs.read()\n",
    "\n",
    "            # if the frame was not grabbed, then we have reached the end\n",
    "            # of the stream\n",
    "            if not grabbed:\n",
    "                break\n",
    "            \n",
    "            # if the frame dimensions are empty, grab them\n",
    "            if W is None or H is None:\n",
    "                (H, W) = frame.shape[:2]\n",
    "\n",
    "            # clone the output frame, then convert it from BGR to RGB\n",
    "            # ordering, resize the frame to a fixed 128x128, and then\n",
    "            # perform mean subtraction\n",
    "\n",
    "            \n",
    "            output = frame.copy()\n",
    "           \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (128, 128)).astype(\"float32\")\n",
    "            frame = frame.reshape(128, 128, 3) / 255\n",
    "\n",
    "            # make predictions on the frame and then update the predictions\n",
    "            # queue\n",
    "            preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "#             print(\"preds\",preds)\n",
    "            Q.append(preds)\n",
    "\n",
    "            # perform prediction averaging over the current history of\n",
    "            # previous predictions\n",
    "            results = np.array(Q).mean(axis=0)\n",
    "            i = (preds > 0.50)[0]\n",
    "            label = i\n",
    "\n",
    "            text_color = (0, 255, 0) # default : green BGR\n",
    "\n",
    "            if label: # Violence prob\n",
    "                text_color = (0, 0, 255) # red\n",
    "\n",
    "            else:\n",
    "                text_color = (0, 255, 0)\n",
    "\n",
    "            text = \"Violence: {}\".format(label)\n",
    "            FONT = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "            cv2.putText(output, text, (35, 50), FONT,1.25, text_color, 3) \n",
    "\n",
    "            # check if the video writer is None\n",
    "            if writer is None:\n",
    "                # initialize our video writer\n",
    "                fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "                writer = cv2.VideoWriter(\"violence_output.avi\", fourcc, 30,(W, H), True)\n",
    "\n",
    "            # write the output frame to disk\n",
    "            writer.write(output)\n",
    "\n",
    "            # show the output image\n",
    "            # cv2_imshow(output)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "        # release the file pointersq\n",
    "        print(\"[INFO] cleaning up...\")\n",
    "        writer.release()\n",
    "        vs.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MxnlB7pOD9uE"
   },
   "outputs": [],
   "source": [
    " V_path = \"violence_1.mp4\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7x2KQ13D_kM",
    "outputId": "cc0132bd-3973-4315-d96f-e6de464a056a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "print_results(V_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q0dO13LYEBZ1",
    "outputId": "11356688-68f8-485f-db46-db5d09e272d0"
   },
   "outputs": [],
   "source": [
    "#Object Detection Model\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "cap = cv2.VideoCapture('violence_output.avi')\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "(height, width)=(None, None)\n",
    "writer = None\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    # height, width, _ = img.shape\n",
    "    \n",
    "    if not _:\n",
    "      break\n",
    "            \n",
    "    # if the frame dimensions are empty, grab them\n",
    "    if width is None or height is None:\n",
    "      (height, width) = img.shape[:2]\n",
    "\n",
    "    out = img.copy()\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (128, 128)).astype(\"float32\")\n",
    "    img = img.reshape(128, 128, 3) / 255\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(out, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(out, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(out, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "    # check if the video writer is None\n",
    "    if writer is None:\n",
    "      # initialize our video writer\n",
    "      fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "      writer = cv2.VideoWriter(\"violence_output_people_detection_1.avi\", fourcc, 30,(width, height), True)\n",
    "      #writer = cv2.VideoWriter(\"violence_output_people_detection_1.avi\", fourcc, 30,(width, height), True)\n",
    "\n",
    "    # write the output frame to disk\n",
    "    writer.write(out)\n",
    "\n",
    "    #cv2_imshow(out)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbDlR1g_lzyP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
